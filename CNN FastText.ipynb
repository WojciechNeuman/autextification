{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e08bc6c",
   "metadata": {
    "id": "6e08bc6c"
   },
   "source": [
    "<center><h1>CNN</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1df9cd",
   "metadata": {
    "id": "0e1df9cd"
   },
   "source": [
    "# Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94226d9d",
   "metadata": {
    "id": "94226d9d"
   },
   "source": [
    "## Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14490533",
   "metadata": {
    "id": "14490533"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547a43f",
   "metadata": {
    "id": "1547a43f"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/competition_2024/preprocessed_data_subtask1/train.csv\").drop(columns='Unnamed: 0')\n",
    "df['label'] = df['label'].map({'human': 0, 'generated': 1})\n",
    "\n",
    "# Concatenate and label data\n",
    "texts = np.array(df.text)\n",
    "labels = np.array(df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f02642",
   "metadata": {
    "id": "90f02642"
   },
   "source": [
    "## Fasttexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96243dd3",
   "metadata": {
    "id": "96243dd3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "\n",
    "URL = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\"\n",
    "FILE = \"fastText\"\n",
    "ZIP_FILE = \"crawl-300d-2M.vec.zip\"\n",
    "\n",
    "if os.path.isdir(FILE):\n",
    "    print(\"fastText exists.\")\n",
    "else:\n",
    "    os.makedirs(FILE, exist_ok=True)\n",
    "    r = requests.get(URL, stream=True)\n",
    "    with open(os.path.join(FILE, ZIP_FILE), 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "    with ZipFile(os.path.join(FILE, ZIP_FILE), 'r') as zip_ref:\n",
    "        zip_ref.extractall(FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df420bf",
   "metadata": {
    "id": "0df420bf"
   },
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286b0d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e286b0d5",
    "outputId": "8895e56e-0a01-4b89-a685-6a689629713e"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94779e3d",
   "metadata": {
    "id": "94779e3d"
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d72c2f",
   "metadata": {
    "id": "47d72c2f"
   },
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a1bc1",
   "metadata": {
    "id": "2f4a1bc1"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "\n",
    "def tokenize(texts):\n",
    "    \"\"\"Tokenize texts, build vocabulary and find maximum sentence length.\n",
    "\n",
    "    Args:\n",
    "        texts (List[str]): List of text data\n",
    "\n",
    "    Returns:\n",
    "        tokenized_texts (List[List[str]]): List of list of tokens\n",
    "        word2idx (Dict): Vocabulary built from the corpus\n",
    "        max_len (int): Maximum sentence length\n",
    "    \"\"\"\n",
    "\n",
    "    max_len = 0\n",
    "    tokenized_texts = []\n",
    "    word2idx = {}\n",
    "\n",
    "    # Add <pad> and <unk> tokens to the vocabulary\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "\n",
    "    # Building our vocab from the corpus starting from index 2\n",
    "    idx = 2\n",
    "    for sent in texts:\n",
    "        tokenized_sent = word_tokenize(sent)\n",
    "\n",
    "        # Add `tokenized_sent` to `tokenized_texts`\n",
    "        tokenized_texts.append(tokenized_sent)\n",
    "\n",
    "        # Add new token to `word2idx`\n",
    "        for token in tokenized_sent:\n",
    "            if token not in word2idx:\n",
    "                word2idx[token] = idx\n",
    "                idx += 1\n",
    "\n",
    "        # Update `max_len`\n",
    "        max_len = max(max_len, len(tokenized_sent))\n",
    "\n",
    "    return tokenized_texts, word2idx, max_len\n",
    "\n",
    "def encode(tokenized_texts, word2idx, max_len):\n",
    "    \"\"\"Pad each sentence to the maximum sentence length and encode tokens to\n",
    "    their index in the vocabulary.\n",
    "\n",
    "    Returns:\n",
    "        input_ids (np.array): Array of token indexes in the vocabulary with\n",
    "            shape (N, max_len). It will the input of our CNN model.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = []\n",
    "    for tokenized_sent in tokenized_texts:\n",
    "        # Pad sentences to max_len\n",
    "        tokenized_sent += ['<pad>'] * (max_len - len(tokenized_sent))\n",
    "\n",
    "        # Encode tokens to input_ids\n",
    "        input_id = [word2idx.get(token) for token in tokenized_sent]\n",
    "        input_ids.append(input_id)\n",
    "\n",
    "    return np.array(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d96cb",
   "metadata": {
    "id": "c04d96cb"
   },
   "source": [
    "## Load Pretrained Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6161b7d",
   "metadata": {
    "id": "e6161b7d"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def load_pretrained_vectors(word2idx, fname):\n",
    "    \"\"\"Load pretrained vectors and create embedding layers.\n",
    "\n",
    "    Args:\n",
    "        word2idx (Dict): Vocabulary built from the corpus\n",
    "        fname (str): Path to pretrained vector file\n",
    "\n",
    "    Returns:\n",
    "        embeddings (np.array): Embedding matrix with shape (N, d) where N is\n",
    "            the size of word2idx and d is embedding dimension\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Loading pretrained vectors...\")\n",
    "    fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "\n",
    "    # Initilize random embeddings\n",
    "    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), d))\n",
    "    embeddings[word2idx['<pad>']] = np.zeros((d,))\n",
    "\n",
    "    # Load pretrained vectors\n",
    "    count = 0\n",
    "    for line in tqdm_notebook(fin):\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        word = tokens[0]\n",
    "        if word in word2idx:\n",
    "            count += 1\n",
    "            embeddings[word2idx[word]] = np.array(tokens[1:], dtype=np.float32)\n",
    "\n",
    "    print(f\"There are {count} / {len(word2idx)} pretrained vectors found.\")\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87edf03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171,
     "referenced_widgets": [
      "17418b94f8cd48e6a4dbf76acc1220e1",
      "dc64753beda9424faff5a57687731034",
      "ff1023f7040745368eb43565c8fea9bd",
      "c4e2ac9deb9540a7ba390fcc1aac8cc5",
      "44b1f7522b204a8f9d879db3daf6e13b",
      "64ab0514b8ae4446bdd06a5ccb6b1018",
      "aac9c475417d44a58b1a1dbe73b83ee4",
      "8aba2915c7f340bbb195acfe0f0d1832",
      "b2c95b3c6b074afe94bc3c2d94e5609a",
      "ddb1c7798af346acbaf7cd25c21c4787",
      "ba316ba2f7934cf0b4389c6937085605"
     ]
    },
    "id": "a87edf03",
    "outputId": "1a1ad7d5-e765-4c2a-8d74-b9d3abb15f15"
   },
   "outputs": [],
   "source": [
    "# Tokenize, build vocabulary, encode tokens\n",
    "print(\"Tokenizing...\\n\")\n",
    "tokenized_texts, word2idx, max_len = tokenize(texts)\n",
    "input_ids = encode(tokenized_texts, word2idx, max_len)\n",
    "\n",
    "# Load pretrained vectors\n",
    "# embeddings = load_pretrained_vectors(word2idx, \"fastText/crawl-300d-2M.vec\")\n",
    "embeddings = load_pretrained_vectors(word2idx, \"./fasttext/wiki.gl/wiki.gl.vec\")\n",
    "# embeddings = load_pretrained_vectors(word2idx, \"drive/MyDrive/PROY/fastText_basque/cc.eu.300.vec\")\n",
    "embeddings = torch.tensor(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a68bf7",
   "metadata": {
    "id": "d5a68bf7"
   },
   "source": [
    "## Create PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592cceb9",
   "metadata": {
    "id": "592cceb9"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import (TensorDataset, DataLoader, RandomSampler,\n",
    "                              SequentialSampler)\n",
    "\n",
    "def data_loader(train_inputs, val_inputs, train_labels, val_labels,\n",
    "                batch_size=50):\n",
    "    \"\"\"Convert train and validation sets to torch.Tensors and load them to\n",
    "    DataLoader.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert data type to torch.Tensor\n",
    "    train_inputs, val_inputs, train_labels, val_labels =\\\n",
    "    tuple(torch.tensor(data) for data in\n",
    "          [train_inputs, val_inputs, train_labels, val_labels])\n",
    "\n",
    "    # Specify batch_size\n",
    "    batch_size = 50\n",
    "\n",
    "    # Create DataLoader for training data\n",
    "    train_data = TensorDataset(train_inputs, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    # Create DataLoader for validation data\n",
    "    val_data = TensorDataset(val_inputs, val_labels)\n",
    "    val_sampler = SequentialSampler(val_data)\n",
    "    val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddd0b5",
   "metadata": {
    "id": "1fddd0b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train Test Split\n",
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
    "    input_ids, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Load data to PyTorch DataLoader\n",
    "train_dataloader, val_dataloader = \\\n",
    "data_loader(train_inputs, val_inputs, train_labels, val_labels, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7950710e",
   "metadata": {
    "id": "7950710e"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24451281",
   "metadata": {
    "id": "24451281"
   },
   "source": [
    "## Create CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65747fc9",
   "metadata": {
    "id": "65747fc9"
   },
   "outputs": [],
   "source": [
    "filter_sizes = [2, 3, 4]\n",
    "num_filters = [2, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7324ccd",
   "metadata": {
    "id": "c7324ccd"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_NLP(nn.Module):\n",
    "    \"\"\"An 1D Convulational Neural Network for Sentence Classification.\"\"\"\n",
    "    def __init__(self,\n",
    "                 pretrained_embedding=None,\n",
    "                 freeze_embedding=False,\n",
    "                 vocab_size=None,\n",
    "                 embed_dim=300,\n",
    "                 filter_sizes=[3, 4, 5],\n",
    "                 num_filters=[100, 100, 100],\n",
    "                 num_classes=2,\n",
    "                 dropout=0.5):\n",
    "        \"\"\"\n",
    "        The constructor for CNN_NLP class.\n",
    "\n",
    "        Args:\n",
    "            pretrained_embedding (torch.Tensor): Pretrained embeddings with\n",
    "                shape (vocab_size, embed_dim)\n",
    "            freeze_embedding (bool): Set to False to fine-tune pretraiend\n",
    "                vectors. Default: False\n",
    "            vocab_size (int): Need to be specified when not pretrained word\n",
    "                embeddings are not used.\n",
    "            embed_dim (int): Dimension of word vectors. Need to be specified\n",
    "                when pretrained word embeddings are not used. Default: 300\n",
    "            filter_sizes (List[int]): List of filter sizes. Default: [3, 4, 5]\n",
    "            num_filters (List[int]): List of number of filters, has the same\n",
    "                length as `filter_sizes`. Default: [100, 100, 100]\n",
    "            n_classes (int): Number of classes. Default: 2\n",
    "            dropout (float): Dropout rate. Default: 0.5\n",
    "        \"\"\"\n",
    "\n",
    "        super(CNN_NLP, self).__init__()\n",
    "        # Embedding layer\n",
    "        if pretrained_embedding is not None:\n",
    "            self.vocab_size, self.embed_dim = pretrained_embedding.shape\n",
    "            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n",
    "                                                          freeze=freeze_embedding)\n",
    "        else:\n",
    "            self.embed_dim = embed_dim\n",
    "            self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                          embedding_dim=self.embed_dim,\n",
    "                                          padding_idx=0,\n",
    "                                          max_norm=5.0)\n",
    "        # Conv Network\n",
    "        self.conv1d_list = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=self.embed_dim,\n",
    "                      out_channels=num_filters[i],\n",
    "                      kernel_size=filter_sizes[i])\n",
    "            for i in range(len(filter_sizes))\n",
    "        ])\n",
    "        # Fully-connected layer and Dropout\n",
    "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        \"\"\"Perform a forward pass through the network.\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): A tensor of token ids with shape\n",
    "                (batch_size, max_sent_length)\n",
    "\n",
    "        Returns:\n",
    "            logits (torch.Tensor): Output logits with shape (batch_size,\n",
    "                n_classes)\n",
    "        \"\"\"\n",
    "\n",
    "        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n",
    "        x_embed = self.embedding(input_ids).float()\n",
    "\n",
    "        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n",
    "        # Output shape: (b, embed_dim, max_len)\n",
    "        x_reshaped = x_embed.permute(0, 2, 1)\n",
    "\n",
    "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
    "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
    "\n",
    "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
    "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
    "            for x_conv in x_conv_list]\n",
    "\n",
    "        # Concatenate x_pool_list to feed the fully connected layer.\n",
    "        # Output shape: (b, sum(num_filters))\n",
    "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
    "                         dim=1)\n",
    "\n",
    "        # Compute logits. Output shape: (b, n_classes)\n",
    "        logits = self.fc(self.dropout(x_fc))\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe3dc1e",
   "metadata": {
    "id": "ebe3dc1e"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c1708",
   "metadata": {
    "id": "687c1708"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def initilize_model(pretrained_embedding=None,\n",
    "                    freeze_embedding=False,\n",
    "                    vocab_size=None,\n",
    "                    embed_dim=300,\n",
    "                    filter_sizes=[3, 4, 5],\n",
    "                    num_filters=[100, 100, 100],\n",
    "                    num_classes=2,\n",
    "                    dropout=0.5,\n",
    "                    learning_rate=0.01):\n",
    "    \"\"\"Instantiate a CNN model and an optimizer.\"\"\"\n",
    "\n",
    "    assert (len(filter_sizes) == len(num_filters)), \"filter_sizes and \\\n",
    "    num_filters need to be of the same length.\"\n",
    "\n",
    "    # Instantiate CNN model\n",
    "    cnn_model = CNN_NLP(pretrained_embedding=pretrained_embedding,\n",
    "                        freeze_embedding=freeze_embedding,\n",
    "                        vocab_size=vocab_size,\n",
    "                        embed_dim=embed_dim,\n",
    "                        filter_sizes=filter_sizes,\n",
    "                        num_filters=num_filters,\n",
    "                        num_classes=2,\n",
    "                        dropout=0.5)\n",
    "\n",
    "    # Send model to `device` (GPU/CPU)\n",
    "    cnn_model.to(device)\n",
    "\n",
    "    # Instantiate Adadelta optimizer\n",
    "    optimizer = optim.Adadelta(cnn_model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               rho=0.95)\n",
    "\n",
    "    return cnn_model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f25ed9",
   "metadata": {
    "id": "b1f25ed9"
   },
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1cf6ac",
   "metadata": {
    "id": "1c1cf6ac"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, optimizer, train_dataloader, val_dataloader=None, epochs=10):\n",
    "    \"\"\"Train the CNN model.\"\"\"\n",
    "\n",
    "    # Tracking best validation accuracy\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "\n",
    "        # Tracking time and loss\n",
    "        t0_epoch = time.time()\n",
    "        total_loss = 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if val_dataloader is not None:\n",
    "            # After the completion of each training epoch, measure the model's\n",
    "            # performance on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Track the best accuracy\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(f\"Training complete! Best accuracy: {best_accuracy:.2f}%.\")\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's\n",
    "    performance on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled\n",
    "    # during the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d693a79",
   "metadata": {
    "id": "0d693a79"
   },
   "source": [
    "### CNN-rand: Word vectors are randomly initialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341549f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e341549f",
    "outputId": "4b55129e-e4c4-4e1f-8118-3bd244aed34e"
   },
   "outputs": [],
   "source": [
    "# CNN-rand: Word vectors are randomly initialized.\n",
    "set_seed(42)\n",
    "cnn_rand, optimizer = initilize_model(vocab_size=len(word2idx),\n",
    "                                      embed_dim=300,\n",
    "                                      learning_rate=0.25,\n",
    "                                      dropout=0.5)\n",
    "train(cnn_rand, optimizer, train_dataloader, val_dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O0IqcPQcSU2U",
   "metadata": {
    "id": "O0IqcPQcSU2U"
   },
   "outputs": [],
   "source": [
    "with open('models/cnn_rand_cc.pkl', 'wb') as file:\n",
    "    pickle.dump(cnn_rand, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01425bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/cnn_rand_cc.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c55e07",
   "metadata": {
    "id": "83c55e07"
   },
   "source": [
    "### CNN-static\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676bbb0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a676bbb0",
    "outputId": "17d3ec50-07e8-45cc-fd5e-308c6e9a86e0"
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "cnn_static, optimizer = initilize_model(pretrained_embedding=embeddings,\n",
    "                                        freeze_embedding=True,\n",
    "                                        learning_rate=0.25,\n",
    "                                        dropout=0.5)\n",
    "train(cnn_static, optimizer, train_dataloader, val_dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G7i1l7eNTh4e",
   "metadata": {
    "id": "G7i1l7eNTh4e"
   },
   "outputs": [],
   "source": [
    "with open('gl_cnn_static_cc.pkl', 'wb') as file:\n",
    "    pickle.dump(cnn_static, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g-d3_0QSNLPK",
   "metadata": {
    "id": "g-d3_0QSNLPK"
   },
   "source": [
    "### CNN-non-static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1jgmPXrCNVlG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jgmPXrCNVlG",
    "outputId": "6785fc2a-3152-4488-e815-8c92354eba38"
   },
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "cnn_non_static, optimizer = initilize_model(pretrained_embedding=embeddings,\n",
    "                                            freeze_embedding=False,\n",
    "                                            learning_rate=0.25,\n",
    "                                            dropout=0.5)\n",
    "train(cnn_non_static, optimizer, train_dataloader, val_dataloader, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oKj9ySLXTlQI",
   "metadata": {
    "id": "oKj9ySLXTlQI"
   },
   "outputs": [],
   "source": [
    "with open('models/gl_cnn_non_static_cc.pkl', 'wb') as file:\n",
    "    pickle.dump(cnn_non_static, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbed96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('models/cnn_non_static_cc.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc6325c",
   "metadata": {
    "id": "cfc6325c"
   },
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f82f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('models/gl_cnn_rand_cc.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff67580",
   "metadata": {
    "id": "aff67580"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "def predict(text, model=cnn_static.to(\"cuda\"), max_len=62):\n",
    "    \"\"\"Predict probability that a review is positive.\"\"\"\n",
    "\n",
    "    # Tokenize, pad and encode text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    padded_tokens = tokens + ['<pad>'] * (max_len - len(tokens))\n",
    "    input_id = [word2idx.get(token, word2idx['<unk>']) for token in padded_tokens]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    input_id = torch.tensor(input_id).unsqueeze(dim=0)\n",
    "\n",
    "    # Compute logits\n",
    "    logits = model.forward(input_id)\n",
    "\n",
    "    #  Compute probability\n",
    "    probs = F.softmax(logits, dim=1).squeeze(dim=0)\n",
    "\n",
    "    # print(f\"This review is {probs[1] * 100:.2f}% AI generated.\")\n",
    "    return probs[1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a036651f",
   "metadata": {
    "id": "a036651f"
   },
   "outputs": [],
   "source": [
    "train_inputs, val_inputs, train_labels, val_labels = train_test_split(\n",
    "    input_ids, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80706284",
   "metadata": {
    "id": "80706284"
   },
   "outputs": [],
   "source": [
    "train_text, val_text, train_etiqueta, val_etiqueta = train_test_split(\n",
    "    df.text, df.label, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c2721",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "338c2721",
    "outputId": "fab85c77-d0f5-477d-f92a-c4874cefe258"
   },
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for text in val_text.tolist():\n",
    "    y_pred.append(predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f105d5",
   "metadata": {
    "id": "52f105d5"
   },
   "outputs": [],
   "source": [
    "valores_numericos = [tensor.item() for tensor in y_pred]\n",
    "\n",
    "# Definir la función de activación paso\n",
    "def step_activation(x, threshold=50):\n",
    "    return 1 if x > threshold else 0\n",
    "\n",
    "# Aplicar la función de activación paso a cada valor\n",
    "y_test_pred_lr = [step_activation(valor) for valor in valores_numericos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad031cea",
   "metadata": {
    "id": "ad031cea",
    "outputId": "11fd6389-9251-4298-8fbe-7e8f43bb8650"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "print(\"=======Accuracy Score===========\")\n",
    "print(metrics.accuracy_score(val_etiqueta, y_test_pred_lr))\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"=======Confusion Matrix===========\")\n",
    "print(metrics.confusion_matrix(val_etiqueta, y_test_pred_lr))\n",
    "\n",
    "# calculate AUC\n",
    "print(\"=======ROC AUC Score===========\")\n",
    "print(metrics.roc_auc_score(val_etiqueta, y_test_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc09433",
   "metadata": {
    "id": "cbc09433",
    "outputId": "140dfb76-7d7e-47ef-d10a-8db7a3ac82cc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1-score for Logistic Regression model: {f1_score(val_etiqueta, y_test_pred_lr, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafd779c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "17418b94f8cd48e6a4dbf76acc1220e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dc64753beda9424faff5a57687731034",
       "IPY_MODEL_ff1023f7040745368eb43565c8fea9bd",
       "IPY_MODEL_c4e2ac9deb9540a7ba390fcc1aac8cc5"
      ],
      "layout": "IPY_MODEL_44b1f7522b204a8f9d879db3daf6e13b"
     }
    },
    "44b1f7522b204a8f9d879db3daf6e13b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64ab0514b8ae4446bdd06a5ccb6b1018": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8aba2915c7f340bbb195acfe0f0d1832": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "aac9c475417d44a58b1a1dbe73b83ee4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2c95b3c6b074afe94bc3c2d94e5609a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ba316ba2f7934cf0b4389c6937085605": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4e2ac9deb9540a7ba390fcc1aac8cc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddb1c7798af346acbaf7cd25c21c4787",
      "placeholder": "​",
      "style": "IPY_MODEL_ba316ba2f7934cf0b4389c6937085605",
      "value": " 167806/? [00:07&lt;00:00, 30582.95it/s]"
     }
    },
    "dc64753beda9424faff5a57687731034": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64ab0514b8ae4446bdd06a5ccb6b1018",
      "placeholder": "​",
      "style": "IPY_MODEL_aac9c475417d44a58b1a1dbe73b83ee4",
      "value": ""
     }
    },
    "ddb1c7798af346acbaf7cd25c21c4787": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff1023f7040745368eb43565c8fea9bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8aba2915c7f340bbb195acfe0f0d1832",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b2c95b3c6b074afe94bc3c2d94e5609a",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
